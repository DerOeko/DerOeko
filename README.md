## Hi there ðŸ‘‹
### Reverse-Engineering Minds ðŸ§ âœ¨

I am fascinated by LLMs. My focus is **mechanistic interpretability**: I want to understand *how* these models make decisions, *why* they work (or fail), and how we can ensure they align with human values. This journey involves dissecting neural circuits, probing for emergent behaviors, and making advanced AI systems more transparent and reliable.

Currently, I investigate the mechanisms of deception and **alignment faking** in LLMs. How do models deceive, and how can we detect it?
Previously, I did computational modelling at the [Motivational and Cognitive Control Lab](https://www.roshancools.com/), Donders Institute, where I explore decision-making circuits in depression.

I am always happy to collaborate. Do reach out if you are passionate mechinterp, deceptive alignment, or alignment. I am particularly keen on empirical projects. See my [research statement](https://docs.google.com/document/d/1UmENQMvMX4sHiuYtsZ_PJ_V95Ygz4LUyxLB5TiugXK8/edit?usp=sharing) for more information on my research interests.

Wanna talk? Feel free to [book a 1-on-1](https://calendar.app.google/3c9J24Pbcb1F558c9) â€“ I'm always open to new perspectives. Or the old fashioned way: samuelgerrit.nellessen{at}gmail.com.

[![trophy](https://github-profile-trophy.vercel.app/?username=DerOeko&theme=onedark)](https://github.com/ryo-ma/github-profile-trophy)
<!--
**DerOeko/DerOeko** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
