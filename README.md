# Hi, I'm Samuel.

I build systems that autonomously find failure modes in Large Language Models using Reinforcement Learning.

Currently, I am working at **Kachman Lab** on **Slingshot**, an automated jailbreaking framework targeting ICML. My work focuses on the intersection of theoretical alignment research and high-performance engineering.

### Current Focus
* **Reinforcement Learning:** Implementing verifiable reward frameworks (using `GRPO` and Verifiers) to train adversarial agents.
* **Inference Optimization:** Designing asynchronous generation pipelines using `asyncio` and `vLLM` to maximize throughput across multi-GPU environments.
* **Evaluation:** Curating adversarial datasets and benchmarking model robustness using `AgentDojo` and custom environments.

### Selected Work
* **Slingshot (Current):** End-to-end RL training for automated jailbreaking.
* **Prime Intellect:** Developed RL environments for decentralized training (e.g., Gutenberg literary analysis).
* **RoboLearn:** Built Bayesian models for depression (controllability) and data analysis pipelines for computational psychiatry (Donders Institute/RadboudUMC).

### Interests
Adversarial Robustness • Model Evals • Alignment Faking • Model Organisms • Mechanistic Interpretability • Steganography • Jailbreaking • Multi-Agent Systems.

---
**Wanna talk?** [Book a 1-on-1](https://calendar.app.google/JA8k9nZCt8k3VjN27) or do it the old fashioned way: `samuelgerrit.nellessen{at}gmail.com`
